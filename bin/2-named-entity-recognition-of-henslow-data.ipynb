{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition of the John Henslow Collection\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## What is Named Entity Recognition (NER)?\n",
    "The purpose of **named entity recognition** is to extract information from unstructured text, especially where it's impractical to have humans read and markup a large number of documents.\n",
    "\n",
    "A named entity can be any type of real-world object or meaningful concept that is assigned a name or a [proper name](https://en.wikipedia.org/wiki/Proper_noun#Proper_names). Typically, named entities can include:\n",
    "\n",
    "- people\n",
    "- organisations\n",
    "- countries\n",
    "- languages\n",
    "- locations\n",
    "- works of art\n",
    "- dates\n",
    "- times\n",
    "- numbers\n",
    "- quantities\n",
    "\n",
    "<p style=\"text-align: center; font-style: italic;\">Examples of possible entities: a person, an organisation and a language (modern or ancient):\n",
    "    </p>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/05/Punjabi_woman_smile.jpg\" alt=\"She was waiting for her turn to participate in 'Gidha' which is the folk dance from the state of Punjab, India, during the Youth Festival in Amritsar. Smile! You Are On! Raminder pal Singh: CC BY-SA 2.0\" title=\"She was waiting for her turn to participate in 'Gidha' which is the folk dance from the state of Punjab, India, during the Youth Festival in Amritsar. Smile! You Are On! Raminder pal Singh: CC BY-SA 2.0\" width=\"100\" style=\"float: left; padding: 10px;\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/World_Health_Organization_Logo.svg/320px-World_Health_Organization_Logo.svg.png\" alt=\"World Health Organisation logo\" title=\"World Health Organisation logo\" width=\"300\" style=\"float: left;  padding: 10px;\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/%D7%94%D7%9E%D7%99%D7%9C%D7%94_%D7%A2%D7%91%D7%A8%D7%99%D7%AA_%D7%91%D7%9B%D7%AA%D7%91_%D7%95%D7%91%D7%9B%D7%AA%D7%91_%D7%94%D7%A2%D7%91%D7%A8%D7%99_%D7%94%D7%A7%D7%93%D7%95%D7%9D.jpg/320px-%D7%94%D7%9E%D7%99%D7%9C%D7%94_%D7%A2%D7%91%D7%A8%D7%99%D7%AA_%D7%91%D7%9B%D7%AA%D7%91_%D7%95%D7%91%D7%9B%D7%AA%D7%91_%D7%94%D7%A2%D7%91%D7%A8%D7%99_%D7%94%D7%A7%D7%93%D7%95%D7%9D.jpg\" alt=\"The word HEBREW written in modern Hebrew language and written in Paleo-Hebrew alphabet. Eliran t: CC BY-SA 4.0\" title=\"The word HEBREW written in modern Hebrew language and written in Paleo-Hebrew alphabet. Eliran t: CC BY-SA 4.0\" width=\"200\" style=\"float: left; padding: 10px;\">\n",
    "\n",
    "<p style=\"clear: left;\">\n",
    "In practice, you can define your own entities that are relevant to the sort of data you are working with. For example, a corpus of archaeological reports might need additional entities for 'culture', 'material' and 'method' in order to extract useful information within the texts.\n",
    "    <p>\n",
    "\n",
    "Recognising named entities means finding and classifying tokens according to the types of entities you have defined. Named entities can be single tokens, such as 'Berlin' (a place), or they can be spans or contiguous sequences of tokens, like 'The Royal Society' (an organisation) and 'Charles Robert Darwin' (a person).\n",
    "        \n",
    "Once you have a corpus tagged with named entities, you could enrich the data further by linking each entity to a corresponding unique identifier from a knowledge base, such as [VIAF](https://viaf.org/). We will cover this further topic in the [last notebook](5-linking-named-entities.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## NER with Machine Learning using spaCy\n",
    "[spaCy](https://spacy.io) is a free and open-source package that can be used to perform automated named entity recognition.\n",
    "\n",
    "If you're interested in learning how to work with spaCy more broadly for a variety of NLP tasks I recommend the beginner's tutorial [Natural Language Processing with spaCy in Python](https://realpython.com/natural-language-processing-spacy-python/) and, for intermediate programmers, the book [Natural Language Processing with Python and spaCy](https://nostarch.com/NLPPython).\n",
    "\n",
    "spaCy uses a form of machine learning called **convolutional neural networks** (CNNs) for named entity recognition. The nature of these neural networks is out of scope for this workshop, but in general terms a CNN produces a **statistical model** that is used to **predict** what are the most likely named entities in a text. This type of machine learning is described as being **supervised**, which means it must be trained on data that has been correctly labelled with named entities before it can do automated labelling on data it's never seen before.\n",
    "\n",
    "As a statistical technique, the predictions might be wrong; in fact, they often are, and it's usually necessary to re-train and adjust the model until its predictions are better. We will cover training a model in the following notebooks.\n",
    "\n",
    "Fortunately, we don't need to start completely from scratch because spaCy provides a range of [pre-trained language models](https://spacy.io/usage/models#languages) for modern languages such as English, Spanish, French and German. For other languages you can train your own and use them with spaCy or re-train one of the existing models.\n",
    "\n",
    "The English models that spaCy offers have been trained on the [OntoNotes corpus](https://catalog.ldc.upenn.edu/LDC2013T19). These models can predict the following entities 'out of the box':\n",
    "\n",
    "<table class=\"_59fbd182\"><thead><tr class=\"_8a68569b\"><th class=\"_2e8d2972\">Type</th><th class=\"_2e8d2972\">Description</th></tr></thead><tbody><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">PERSON</code></td><td class=\"_5c99da9a\">People, including fictional.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">NORP</code></td><td class=\"_5c99da9a\">Nationalities or religious or political groups.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">FAC</code></td><td class=\"_5c99da9a\">Buildings, airports, highways, bridges, etc.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">ORG</code></td><td class=\"_5c99da9a\">Companies, agencies, institutions, etc.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">GPE</code></td><td class=\"_5c99da9a\">Countries, cities, states.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">LOC</code></td><td class=\"_5c99da9a\">Non-GPE locations, mountain ranges, bodies of water.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">PRODUCT</code></td><td class=\"_5c99da9a\">Objects, vehicles, foods, etc. (Not services.)</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">EVENT</code></td><td class=\"_5c99da9a\">Named hurricanes, battles, wars, sports events, etc.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">WORK_OF_ART</code></td><td class=\"_5c99da9a\">Titles of books, songs, etc.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">LAW</code></td><td class=\"_5c99da9a\">Named documents made into laws.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">LANGUAGE</code></td><td class=\"_5c99da9a\">Any named language.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">DATE</code></td><td class=\"_5c99da9a\">Absolute or relative dates or periods.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">TIME</code></td><td class=\"_5c99da9a\">Times smaller than a day.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">PERCENT</code></td><td class=\"_5c99da9a\">Percentage, including ”%“.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">MONEY</code></td><td class=\"_5c99da9a\">Monetary values, including unit.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">QUANTITY</code></td><td class=\"_5c99da9a\">Measurements, as of weight or distance.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">ORDINAL</code></td><td class=\"_5c99da9a\">“first”, “second”, etc.</td></tr><tr class=\"_8a68569b\"><td class=\"_5c99da9a\"><code class=\"_1d7c6046\">CARDINAL</code></td><td class=\"_5c99da9a\">Numerals that do not fall under another type.</td></tr></tbody></table>\n",
    "\n",
    "For more detail about how to use spaCy for NER, see the documentation [Named Entity Recognition 101](https://spacy.io/usage/linguistic-features#named-entities-101).\n",
    "\n",
    "An alternative to spaCy is [Natural Language Toolkit (NLTK)](https://www.nltk.org/), which was the first open-source Python library for NLP, originally released in 2001. It is still a valuable tool for teaching and research and has better support in the community for older and non-Indo-European languages; but spaCy is easier to use and faster, which is why I'm using it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## NER in Practice: A Letter from William Christy, Jr.,  to John Henslow \n",
    "Included with these Jupyter notebooks are a set of data from the Henslow Correspondence Project (HCP), which locates and transcribes the letters of the botanist and mineralogist, [John Stevens Henslow](https://www.darwinproject.ac.uk/john-stevens-henslow) (1796–1861). John Henslow was professor of Botany and Mineralogy at the University of Cambridge, and mentor and friend to Charles Darwin; they exchanged significant letters throughout their lives.\n",
    "\n",
    "<a href=\"http://resource.nlm.nih.gov/101418379\"><img src=\"https://epsilon.ac.uk/css/images/henslow.jpg\" alt=\"Portrait of J.S. Henslow, by T.H. Maguire, 1851. Half-length, seated, full face; arm resting on books on table; holding spectacles.\" title=\"Portrait of J.S. Henslow, by T.H. Maguire, 1851. Half-length, seated, full face; arm resting on books on table; holding spectacles.\" width=\"250\"></a>\n",
    "<p style=\"text-align: center; font-style: italic;\">Portrait of J.S. Henslow, by T.H. Maguire, 1851.</p>\n",
    "\n",
    "The latest release of letters can be viewed on [Epsilon](https://epsilon.ac.uk/search?sort=date;f1-collection=John%20Henslow), a collaborative platform for reuniting nineteenth-century letters of science.\n",
    "\n",
    "> **Content warning**: The HCP letters were written during the period of British imperialism, therefore some of the correspondence contains content we now find offensive, for example, `letters_138.xml` contains a racist description. These Jupyter notebooks do not contain or discuss any of this material, but please be aware you may come across it if you browse through the letters independently.\n",
    "\n",
    "You can browse the letters included with these notebooks by clicking this link to the folder: [`data/henslow`](data/henslow/) \n",
    "\n",
    "The letters are included here courtesy of HCP and under [Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/).\n",
    "\n",
    "---\n",
    "---\n",
    "## Inspecting the Letter XML\n",
    "\n",
    "We start with a letter William Christy, Jr. sent to Henslow in 1831 in which he discusses sending and receiving rare plant specimens, including the rather delightful *Arbutus unedo* (Strawberry tree).\n",
    "\n",
    "<a title=\"Arbutus berries (Palombaggia, Corsica). Jplm, Public domain, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Arbouses.jpg\"><img width=\"256\" alt=\"Arbutus berries (Palombaggia, Corsica)\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Arbouses.jpg/256px-Arbouses.jpg\"></a>\n",
    "<p style=\"text-align: center; font-style: italic;\">Arbutus berries (Palombaggia, Corsica)</p>\n",
    "\n",
    "Christy was a Fellow of the Linnean Society and a non-resident member of the Botanical Society of Edinburgh.\n",
    "\n",
    "---\n",
    "> **EXERCISE**: Open the letter now in your browser by clicking this link: [`letters_152.xml`](data/henslow/letters_152.xml).\n",
    "\n",
    "---\n",
    "\n",
    "Your browser should try to display the XML in a relatively friendly form.\n",
    "As you scroll down the letter, notice the various types of information that are marked up in the `<teiHeader>`. Collapse or scroll past the `<teiHeader>` to the `<text>` element where the body of the letter itself is marked up. We are interested in the contents of **`<div type=\"transcription\">`**.\n",
    "\n",
    "Christy begins:\n",
    "\n",
    "> *I am ashamed that I have never before acknowledged the receipt of the very valuable packet of specimens you were so kind as to send me. Having now got my plants up from Cheshire I shall lose no time in making up a parcel for you.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Opening the Letter with Beautiful Soup\n",
    "[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a library for getting data out of HTML and XML documents. It makes it easy to search documents for particular information. It's often used for *web scraping*, which involves harvesting data from websites automatically. It can also be used to extract information from plain XML files, which is how we will be using it here.\n",
    "\n",
    "First we import what we need from the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we open the letter using the `open()` function and pass the file into `BeautifulSoup`. This is jokingly called \"making the soup\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/henslow/letters_152.xml\", encoding=\"utf-8\") as file:\n",
    "    letter = BeautifulSoup(file, \"lxml-xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The letter has been opened, parsed by `BeautifulSoup` and stored with the name `letter`. Print out the text of the letter below to check the XML is what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<?xml-model href=\"schema/tei_all.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?><!--OLD FILENAME:letters_152.xml--><TEI xml:id=\"HENSLOW-152\" xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
       "<teiHeader>\n",
       "<fileDesc>\n",
       "<titleStmt>\n",
       "<title xml:id=\"main_title\">From William Christy Jr   26 February 1831</title>\n",
       "</titleStmt>\n",
       "<publicationStmt>\n",
       "<authority>Henslow Correspondence Project</authority>\n",
       "<publisher>Henslow Correspondence Project</publisher>\n",
       "<pubPlace>Cambridge</pubPlace>\n",
       "<availability status=\"restricted\">\n",
       "<p>Available under license only</p>\n",
       "</availability>\n",
       "<availability status=\"restricted\" xml:id=\"displayImageRights\">\n",
       "<p>Zooming image © Cambridge University Library, All rights reserved.</p>\n",
       "</availability>\n",
       "<availability status=\"restricted\" xml:id=\"downloadImageRights\">\n",
       "<licence>This image may be used in accord with fair use and fair dealing provisions, including teaching and research. If you wish to reproduce it within publications or on the public web, please make a reproduction request.</licence>\n",
       "</availability>\n",
       "<availability status=\"restricted\" xml:id=\"metadataRights\">\n",
       "<licence target=\"https://creativecommons.org/licenses/by-nc/4.0/\">This metadata is licensed under a Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0).</licence>\n",
       "</availability>\n",
       "</publicationStmt>\n",
       "<sourceDesc>\n",
       "<msDesc>\n",
       "<msIdentifier>\n",
       "<repository>Cambridge University Library</repository>\n",
       "<idno>MS Add. 8176: 183</idno>\n",
       "</msIdentifier>\n",
       "<msContents>\n",
       "<msItem>\n",
       "<title copyOf=\"#main_title\"/>\n",
       "</msItem>\n",
       "</msContents>\n",
       "</msDesc>\n",
       "</sourceDesc>\n",
       "</fileDesc>\n",
       "<profileDesc>\n",
       "<correspDesc>\n",
       "<correspAction type=\"sent\">\n",
       "<persName key=\"../nameregs/nameregs_81.xml\">Christy Jr, William</persName>\n",
       "<date when=\"1831-02-26\">26 February 1831</date>\n",
       "</correspAction>\n",
       "<correspAction type=\"received\">\n",
       "<persName key=\"../nameregs/nameregs_1.xml\">Henslow, J. S.</persName>\n",
       "</correspAction>\n",
       "</correspDesc>\n",
       "</profileDesc>\n",
       "<revisionDesc>\n",
       "<change when=\"2014-06-06\">Converted to XML by <name xml:id=\"hjones\">Huw Jones</name>\n",
       "</change>\n",
       "<change when=\"2016-05-17\">Converted to TEI P5 by <name xml:id=\"mjhawkins\">Michael Hawkins</name>\n",
       "</change>\n",
       "<change status=\"released\" type=\"letter\" when=\"2020-08-10\">Transcription cleared for online release</change>\n",
       "</revisionDesc>\n",
       "</teiHeader>\n",
       "<text>\n",
       "<body>\n",
       "<div type=\"letter\">\n",
       "<div type=\"text\">\n",
       "<opener>\n",
       "<placeName>Clapham Road</placeName>\n",
       "<date>26 February 1831</date>\n",
       "<salute>My dear Sir</salute>\n",
       "</opener>\n",
       "<div type=\"transcription\">\n",
       "<p>I am ashamed that I have never before acknowledged the receipt of the very valuable packet of specimens you were so kind as to send me. Having now got my plants up from Cheshire I shall lose no time in making up a parcel for you. By some mistake the packet containing my Irish plants is not with the rest. Of these the only really rare ones are Arbutus unedo, Stachys ambigua &amp; Trichomanes brevisetum. The first &amp; last I gathered with Wilson so you have perhaps already received them from him but the other I think he did not find. I shall therefore if they do not arrive in time for this parcel enclose them in another before the season is over as there are some of your desiderata of which I have no duplicates by me but which I can easily procure in the ensuing Spring &amp; Summer.</p>\n",
       "<p>In sending you parcels I shall not conform myself strictly to your desiderata but send you duplicates of rare or local plants which if you already possess you can give to the best Botanists of the Class or dispose of in exchanges or in any other way you think fit.</p>\n",
       "<p>I received a very long &amp; interesting letter from Wilson a few days ago full of valuable remarks on various plants. I also had a very precious parcel of specimens from the Rev <hi rend=\"superscript\">d</hi> G E Smith containing among others Cyperus longus &amp; Orobanche caryophyllacea. Is he a correspondent of yours? I think he could send you a good many rare plants.</p>\n",
       "<p>If you are not already acquainted with my friend Mr Arnott of Edinburgh I strongly advise you to open a correspondence with him.</p>\n",
       "<p>He has botanized extensively with M <hi rend=\"superscript\">r</hi> Bentham in the South of France &amp; Pyrenees &amp; wants to send you a very valuable collection of the plants of that part of Europe as well as some rare British ones.</p>\n",
       "<p>I know he is in want of some of the rare Cambridge Plants &amp; when I was in Edinburgh he talked of writing to you &amp; offering to exchange Exotic Plants for these.</p>\n",
       "<p>Perhaps he has already done so. His address is G A Walker Arnott Esq., Advocate, 7 S <hi rend=\"superscript\">t</hi> John Street Edinburgh.</p>\n",
       "<p>Excuse the freedom of my remarks – I am only anxious to shew you every opportunity of benefiting your Herbarium. By the bye would any seeds from Barbadoes be useful to your Botanic Garden? I have just received some but unfortunately without their scientific names.</p>\n",
       "<p>Some of the local names are odd enough as “Old Maids” – “Pigeons dung” &amp;c &amp;c &amp;c Perhaps you will let me know.</p>\n",
       "<p>There is one marked “plant from which Noyau is made” – it is evidently the seed of a species of Ipomea or Convolvulus &amp; besides abounding in prussic acid contains a great deal of saccharine matter. I enclose a few if you like to grow it.</p>\n",
       "<p>Believe me | yours very truly | W Christy Jr</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</body>\n",
       "</text>\n",
       "</TEI>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we inspected the XML before, we saw that the actual content of Christy's letter is in the `<div>` element with the attribute `type` that has the value `\"transcription\"`. \n",
    "\n",
    "Beautiful Soup allows us to pick out text from a document by element, attribute and/or value. In this case, we will use the **`find()`** method and pass in what we are looking for: an element with the `type` attribute and the value `\"transcription\"`. \n",
    "\n",
    "We only want the textual content, not the whole element including the tag, so we access the `text` attribute.\n",
    "\n",
    "Feel free to experiment and find out what happens if you miss off the attribute `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2641"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription = letter.find(type='transcription').text\n",
    "len(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you isolate text from other elements in the letter instead? Refer to the Beautiful Soup documentation on [Searching the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Transcription\n",
    "\n",
    "One small point of cleaning we will do now will make a big difference to the quality of NER later on. The style of writing in these letters is to replace the word 'and' with the ampersand (`&`). Experience tells me that spaCy's language model doesn't handle this very well because it is different in style to the texts it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = transcription.replace('& ', 'and ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would instead re-train the language model to better understand the use of ampersands. In this notebook, I just want to show you a good example.\n",
    "\n",
    "As you follow along, you may notice more aspects of the text that could or should be cleaned. Do make a note of your thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## A Pre-Trained Language Model\n",
    "\n",
    "We can now move into the named entity recognition using spaCy. We are going to use a pre-trained English language model provided by spaCy called `'en_core_web_sm'`. The elements of this model's name break down as follows:\n",
    "\n",
    "* `'en'`: the language code, in this case, English\n",
    "* `'core'`: the capabilities for the model - 'core' is general purpose \n",
    "* `'web'`: the type of text the model was trained on\n",
    "* `'sm'`: how large the model is when stored on disk - 'sm' means small\n",
    "\n",
    "A full list of the [available pre-trained language models](https://spacy.io/usage/models#languages) is available.\n",
    "\n",
    "To start, we import and load the pre-trained English language model and give it the name `nlp`, ready to do the work on the transcription. (The name could be anything, but `nlp` is used by convention, and you will see this name used in examples and tutorials.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, let's take a moment to examine the metadata of this language model, and remind ourselves of what it consists. We can do this with the `meta` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lang': 'en',\n",
       " 'name': 'core_web_sm',\n",
       " 'version': '3.3.0',\n",
       " 'description': 'English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.',\n",
       " 'author': 'Explosion',\n",
       " 'email': 'contact@explosion.ai',\n",
       " 'url': 'https://explosion.ai',\n",
       " 'license': 'MIT',\n",
       " 'spacy_version': '>=3.3.0.dev0,<3.4.0',\n",
       " 'spacy_git_version': '849bef2de',\n",
       " 'vectors': {'width': 0,\n",
       "  'vectors': 0,\n",
       "  'keys': 0,\n",
       "  'name': None,\n",
       "  'mode': 'default'},\n",
       " 'labels': {'tok2vec': [],\n",
       "  'tagger': ['$',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   '-LRB-',\n",
       "   '-RRB-',\n",
       "   '.',\n",
       "   ':',\n",
       "   'ADD',\n",
       "   'AFX',\n",
       "   'CC',\n",
       "   'CD',\n",
       "   'DT',\n",
       "   'EX',\n",
       "   'FW',\n",
       "   'HYPH',\n",
       "   'IN',\n",
       "   'JJ',\n",
       "   'JJR',\n",
       "   'JJS',\n",
       "   'LS',\n",
       "   'MD',\n",
       "   'NFP',\n",
       "   'NN',\n",
       "   'NNP',\n",
       "   'NNPS',\n",
       "   'NNS',\n",
       "   'PDT',\n",
       "   'POS',\n",
       "   'PRP',\n",
       "   'PRP$',\n",
       "   'RB',\n",
       "   'RBR',\n",
       "   'RBS',\n",
       "   'RP',\n",
       "   'SYM',\n",
       "   'TO',\n",
       "   'UH',\n",
       "   'VB',\n",
       "   'VBD',\n",
       "   'VBG',\n",
       "   'VBN',\n",
       "   'VBP',\n",
       "   'VBZ',\n",
       "   'WDT',\n",
       "   'WP',\n",
       "   'WP$',\n",
       "   'WRB',\n",
       "   'XX',\n",
       "   '``'],\n",
       "  'parser': ['ROOT',\n",
       "   'acl',\n",
       "   'acomp',\n",
       "   'advcl',\n",
       "   'advmod',\n",
       "   'agent',\n",
       "   'amod',\n",
       "   'appos',\n",
       "   'attr',\n",
       "   'aux',\n",
       "   'auxpass',\n",
       "   'case',\n",
       "   'cc',\n",
       "   'ccomp',\n",
       "   'compound',\n",
       "   'conj',\n",
       "   'csubj',\n",
       "   'csubjpass',\n",
       "   'dative',\n",
       "   'dep',\n",
       "   'det',\n",
       "   'dobj',\n",
       "   'expl',\n",
       "   'intj',\n",
       "   'mark',\n",
       "   'meta',\n",
       "   'neg',\n",
       "   'nmod',\n",
       "   'npadvmod',\n",
       "   'nsubj',\n",
       "   'nsubjpass',\n",
       "   'nummod',\n",
       "   'oprd',\n",
       "   'parataxis',\n",
       "   'pcomp',\n",
       "   'pobj',\n",
       "   'poss',\n",
       "   'preconj',\n",
       "   'predet',\n",
       "   'prep',\n",
       "   'prt',\n",
       "   'punct',\n",
       "   'quantmod',\n",
       "   'relcl',\n",
       "   'xcomp'],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': ['CARDINAL',\n",
       "   'DATE',\n",
       "   'EVENT',\n",
       "   'FAC',\n",
       "   'GPE',\n",
       "   'LANGUAGE',\n",
       "   'LAW',\n",
       "   'LOC',\n",
       "   'MONEY',\n",
       "   'NORP',\n",
       "   'ORDINAL',\n",
       "   'ORG',\n",
       "   'PERCENT',\n",
       "   'PERSON',\n",
       "   'PRODUCT',\n",
       "   'QUANTITY',\n",
       "   'TIME',\n",
       "   'WORK_OF_ART']},\n",
       " 'pipeline': ['tok2vec',\n",
       "  'tagger',\n",
       "  'parser',\n",
       "  'attribute_ruler',\n",
       "  'lemmatizer',\n",
       "  'ner'],\n",
       " 'components': ['tok2vec',\n",
       "  'tagger',\n",
       "  'parser',\n",
       "  'senter',\n",
       "  'attribute_ruler',\n",
       "  'lemmatizer',\n",
       "  'ner'],\n",
       " 'disabled': ['senter'],\n",
       " 'performance': {'token_acc': 0.9993092439000001,\n",
       "  'token_p': 0.9956819193,\n",
       "  'token_r': 0.9957659295000001,\n",
       "  'token_f': 0.9957239226000001,\n",
       "  'tag_acc': 0.9726545475,\n",
       "  'sents_p': 0.9188657486,\n",
       "  'sents_r': 0.8935285969000001,\n",
       "  'sents_f': 0.9060200669,\n",
       "  'dep_uas': 0.9180803841,\n",
       "  'dep_las': 0.8996666011000001,\n",
       "  'dep_las_per_type': {'prep': {'p': 0.8545638793,\n",
       "    'r': 0.8639347372,\n",
       "    'f': 0.8592237589},\n",
       "   'det': {'p': 0.9767252604000001, 'r': 0.9787164642, 'f': 0.9777198485},\n",
       "   'pobj': {'p': 0.9624306803,\n",
       "    'r': 0.9677596701000001,\n",
       "    'f': 0.9650878189000001},\n",
       "   'nsubj': {'p': 0.9570163789,\n",
       "    'r': 0.9471631982000001,\n",
       "    'f': 0.9520642959000001},\n",
       "   'aux': {'p': 0.9800017776000001,\n",
       "    'r': 0.9815721535,\n",
       "    'f': 0.9807863370000001},\n",
       "   'advmod': {'p': 0.8575166709, 'r': 0.8547030119, 'f': 0.8561075296},\n",
       "   'relcl': {'p': 0.7630824373, 'r': 0.7724963716000001, 'f': 0.7677605481},\n",
       "   'root': {'p': 0.9153887909, 'r': 0.8899663566, 'f': 0.9024985785},\n",
       "   'xcomp': {'p': 0.8755679832000001,\n",
       "    'r': 0.8991385499000001,\n",
       "    'f': 0.8871967416000001},\n",
       "   'amod': {'p': 0.9161676647, 'r': 0.9119533528, 'f': 0.9140556512},\n",
       "   'compound': {'p': 0.9153947513, 'r': 0.9285475607, 'f': 0.9219242466},\n",
       "   'poss': {'p': 0.9729241877, 'r': 0.9764492754, 'f': 0.9746835443},\n",
       "   'ccomp': {'p': 0.7720643231000001,\n",
       "    'r': 0.8409368635000001,\n",
       "    'f': 0.8050302203},\n",
       "   'attr': {'p': 0.9093147312000001, 'r': 0.9318755257, 'f': 0.9204569055},\n",
       "   'case': {'p': 0.977799704, 'r': 0.9919919920000001, 'f': 0.9848447205},\n",
       "   'mark': {'p': 0.9035921817, 'r': 0.9064652888, 'f': 0.905026455},\n",
       "   'intj': {'p': 0.6711250983, 'r': 0.6249084249, 'f': 0.6471927162000001},\n",
       "   'advcl': {'p': 0.6756965944000001, 'r': 0.6595316041, 'f': 0.6675162482},\n",
       "   'cc': {'p': 0.8375451264, 'r': 0.8324363114000001, 'f': 0.8349829044},\n",
       "   'neg': {'p': 0.9480778832000001, 'r': 0.9528349222, 'f': 0.9504504505},\n",
       "   'conj': {'p': 0.7654719087, 'r': 0.77693857, 'f': 0.7711626164000001},\n",
       "   'nsubjpass': {'p': 0.9168804515000001,\n",
       "    'r': 0.9164102564000001,\n",
       "    'f': 0.9166452937},\n",
       "   'auxpass': {'p': 0.9459821429, 'r': 0.9653758542, 'f': 0.9555806088000001},\n",
       "   'dobj': {'p': 0.9223308565, 'r': 0.9396764682000001, 'f': 0.9309228705},\n",
       "   'nummod': {'p': 0.9368956743, 'r': 0.9297979798, 'f': 0.9333333333},\n",
       "   'npadvmod': {'p': 0.7781178271, 'r': 0.7225577265, 'f': 0.7493092651000001},\n",
       "   'prt': {'p': 0.816091954, 'r': 0.8906810036, 'f': 0.851756641},\n",
       "   'pcomp': {'p': 0.8699300699, 'r': 0.8711484594000001, 'f': 0.8705388383},\n",
       "   'expl': {'p': 0.9830148620000001,\n",
       "    'r': 0.9914346895,\n",
       "    'f': 0.9872068230000001},\n",
       "   'acl': {'p': 0.7332949309, 'r': 0.6944899073, 'f': 0.7133650883},\n",
       "   'agent': {'p': 0.8885135135000001, 'r': 0.9426523297, 'f': 0.9147826087},\n",
       "   'dative': {'p': 0.7847769029, 'r': 0.6857798165, 'f': 0.7319461444},\n",
       "   'acomp': {'p': 0.9046746104000001,\n",
       "    'r': 0.8952380952000001,\n",
       "    'f': 0.8999316161},\n",
       "   'dep': {'p': 0.41516245490000003,\n",
       "    'r': 0.1866883117,\n",
       "    'f': 0.25755879060000003},\n",
       "   'csubj': {'p': 0.6476683938000001, 'r': 0.7396449704, 'f': 0.6906077348},\n",
       "   'quantmod': {'p': 0.8682310469000001,\n",
       "    'r': 0.7814784728,\n",
       "    'f': 0.8225737495000001},\n",
       "   'nmod': {'p': 0.741078208, 'r': 0.5947592931, 'f': 0.6599053414},\n",
       "   'appos': {'p': 0.7215189873000001, 'r': 0.6676789588, 'f': 0.6935556557},\n",
       "   'predet': {'p': 0.8395061728000001, 'r': 0.8755364807, 'f': 0.8571428571},\n",
       "   'preconj': {'p': 0.5544554455, 'r': 0.6511627907, 'f': 0.5989304813},\n",
       "   'oprd': {'p': 0.8205980066, 'r': 0.7373134328000001, 'f': 0.7767295597},\n",
       "   'parataxis': {'p': 0.6121883657, 'r': 0.4793926247, 'f': 0.5377128954},\n",
       "   'meta': {'p': 0.7407407407000001, 'r': 0.3846153846, 'f': 0.5063291139},\n",
       "   'csubjpass': {'p': 0.7142857143, 'r': 0.8333333333, 'f': 0.7692307692}},\n",
       "  'ents_p': 0.8508041869,\n",
       "  'ents_r': 0.8344851763000001,\n",
       "  'ents_f': 0.8425656714,\n",
       "  'ents_per_type': {'DATE': {'p': 0.8732394366,\n",
       "    'r': 0.8660317460000001,\n",
       "    'f': 0.8696206567},\n",
       "   'GPE': {'p': 0.9154443486, 'r': 0.8878661088, 'f': 0.90144435},\n",
       "   'ORDINAL': {'p': 0.7927927928, 'r': 0.8198757764, 'f': 0.8061068702},\n",
       "   'FAC': {'p': 0.4049586777, 'r': 0.3769230769, 'f': 0.390438247},\n",
       "   'ORG': {'p': 0.8038601982, 'r': 0.8170731707000001, 'f': 0.810412832},\n",
       "   'CARDINAL': {'p': 0.8222477064, 'r': 0.8525564804, 'f': 0.8371278459},\n",
       "   'LOC': {'p': 0.714801444, 'r': 0.6305732484000001, 'f': 0.6700507614},\n",
       "   'PERSON': {'p': 0.8572793883000001,\n",
       "    'r': 0.8782637076,\n",
       "    'f': 0.8676446881000001},\n",
       "   'NORP': {'p': 0.918652424, 'r': 0.8944000000000001, 'f': 0.9063640049},\n",
       "   'TIME': {'p': 0.7436708861, 'r': 0.6871345029, 'f': 0.7142857143},\n",
       "   'QUANTITY': {'p': 0.8308823529, 'r': 0.6208791209, 'f': 0.7106918239000001},\n",
       "   'EVENT': {'p': 0.5533980583, 'r': 0.3275862069, 'f': 0.4115523466},\n",
       "   'WORK_OF_ART': {'p': 0.49264705880000004,\n",
       "    'r': 0.3453608247,\n",
       "    'f': 0.4060606061},\n",
       "   'LAW': {'p': 0.58, 'r': 0.453125, 'f': 0.5087719298},\n",
       "   'MONEY': {'p': 0.9198564593, 'r': 0.9079102715, 'f': 0.9138443256000001},\n",
       "   'PERCENT': {'p': 0.9153354633, 'r': 0.8774885145, 'f': 0.8960125098},\n",
       "   'LANGUAGE': {'p': 0.7857142857, 'r': 0.6875, 'f': 0.7333333333000001},\n",
       "   'PRODUCT': {'p': 0.5795454545000001, 'r': 0.2417061611, 'f': 0.3411371237}},\n",
       "  'speed': 9738.3022066337},\n",
       " 'sources': [{'name': 'OntoNotes 5',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC2013T19',\n",
       "   'license': 'commercial (licensed by Explosion)',\n",
       "   'author': 'Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, Ann Houston'},\n",
       "  {'name': 'ClearNLP Constituent-to-Dependency Conversion',\n",
       "   'url': 'https://github.com/clir/clearnlp-guidelines/blob/master/md/components/dependency_conversion.md',\n",
       "   'license': 'Citation provided for reference, no code packaged with model',\n",
       "   'author': 'Emory University'},\n",
       "  {'name': 'WordNet 3.0',\n",
       "   'url': 'https://wordnet.princeton.edu/',\n",
       "   'author': 'Princeton University',\n",
       "   'license': 'WordNet 3.0 License'}],\n",
       " 'requirements': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scroll through this metadata and in particular note the `'description'` and `'sources'`, including information on what data the model is trained on, and `'ner'` labels, which should match those listed near the top of this notebook.\n",
    "\n",
    "If you have forgotten already what a label stands for (some of them are rather cryptic!) then you can ask spaCy to give you a human-readable explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buildings, airports, highways, bridges, etc.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.explain('FAC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also the `'performance'` statistics, for your interest. The ones relevant to us are:\n",
    "\n",
    "`'ents_p': 0.8508041869,\n",
    " 'ents_r': 0.8344851763000001,\n",
    " 'ents_f': 0.8425656714`\n",
    "\n",
    "These were created when the model was evaluated and give you an idea of how well it performs. `'ents_p'`, `'ents_r'`, `'ents_f'` stand for \"precision\", \"recall\" and \"fscore\", respectively.\n",
    "\n",
    "**Precision** is the percentage of entities predicted that are actually relevant (_aka_ \"positive predictive value\"); **recall** is the percentage of relevant entities that were actually predicted (_aka_ \"sensitivity\"); the **fscore** combines the precision and recall into a single average score.\n",
    "\n",
    "Put rather simplistically, we can say that this model is about 85% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Recognising Named Entities with spaCy\n",
    "\n",
    "Now, we can pass the transcription into the language model and spaCy does the rest. It returns to us a `Doc` object (which we name `document`) that contains all the **tokens** and **annotations** it has created. We print out the document text stored on the attribute `text` just to check that spaCy has correctly parsed the transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI am ashamed that I have never before acknowledged the receipt of the very valuable packet of specimens you were so kind as to send me. Having now got my plants up from Cheshire I shall lose no time in making up a parcel for you. By some mistake the packet containing my Irish plants is not with the rest. Of these the only really rare ones are Arbutus unedo, Stachys ambigua and Trichomanes brevisetum. The first and last I gathered with Wilson so you have perhaps already received them from him but the other I think he did not find. I shall therefore if they do not arrive in time for this parcel enclose them in another before the season is over as there are some of your desiderata of which I have no duplicates by me but which I can easily procure in the ensuing Spring and Summer.\\nIn sending you parcels I shall not conform myself strictly to your desiderata but send you duplicates of rare or local plants which if you already possess you can give to the best Botanists of the Class or dispose of in exchanges or in any other way you think fit.\\nI received a very long and interesting letter from Wilson a few days ago full of valuable remarks on various plants. I also had a very precious parcel of specimens from the Rev d G E Smith containing among others Cyperus longus and Orobanche caryophyllacea. Is he a correspondent of yours? I think he could send you a good many rare plants.\\nIf you are not already acquainted with my friend Mr Arnott of Edinburgh I strongly advise you to open a correspondence with him.\\nHe has botanized extensively with M r Bentham in the South of France and Pyrenees and wants to send you a very valuable collection of the plants of that part of Europe as well as some rare British ones.\\nI know he is in want of some of the rare Cambridge Plants and when I was in Edinburgh he talked of writing to you and offering to exchange Exotic Plants for these.\\nPerhaps he has already done so. His address is G A Walker Arnott Esq., Advocate, 7 S t John Street Edinburgh.\\nExcuse the freedom of my remarks – I am only anxious to shew you every opportunity of benefiting your Herbarium. By the bye would any seeds from Barbadoes be useful to your Botanic Garden? I have just received some but unfortunately without their scientific names.\\nSome of the local names are odd enough as “Old Maids” – “Pigeons dung” &c &c &c Perhaps you will let me know.\\nThere is one marked “plant from which Noyau is made” – it is evidently the seed of a species of Ipomea or Convolvulus and besides abounding in prussic acid contains a great deal of saccharine matter. I enclose a few if you like to grow it.\\nBelieve me | yours very truly | W Christy Jr\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = nlp(transcription)\n",
    "document.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what has actually happened? Behind the scenes spaCy has done the following tasks:\n",
    "\n",
    "* part-of-speech tagging (`'tagger'`)\n",
    "* syntactic dependency parsing (`'parser'`)\n",
    "* lemmatizing (`'lemmatizer'`)\n",
    "* named entity recognition (`'ner'`)\n",
    "\n",
    "This series of tasks is called a **processing pipeline** and each individual task is known as a **component**.\n",
    "\n",
    "<img src=\"https://spacy.io/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg\" alt=\"Default spaCy processing pipeline\" title=\"Default spaCy processing pipeline\">\n",
    "\n",
    "Of all these components (tasks), the tokenizer is essential and must happen for every pipeline; the rest are optional, depending on what you want to do with your text.\n",
    "\n",
    "In the metadata for this model (`nlp.meta` above), you can see listed the pipeline components:\n",
    "\n",
    "`'pipeline': ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']`\n",
    "\n",
    "This is the default processing pipeline included with the `'en_core_web_sm'` language model. You can read more about [spaCy Processing Pipelines](https://spacy.io/usage/processing-pipelines).\n",
    "\n",
    "As we only need the `'ner'` component, we could speed up our code by disabling the attribute_ruler and the parser like this:\n",
    "\n",
    "`nlp = en_core_web_sm.load(disable=['attribute_ruler', 'parser'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to compare the performance of the model with and without the unnecessary components\n",
    "# Hint: you could use the Jupyter magic command `%%time` or `import time` and use `time.time()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to inspect the data. All the named entities are available on the `ents` attribute. The following code loops over all the named entities and prints each of them out with the labels that spaCy has predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irish: NORP\n",
      "Arbutus: NORP\n",
      "Trichomanes: PRODUCT\n",
      "first: ORDINAL\n",
      "Wilson: PERSON\n",
      "Spring: DATE\n",
      "Wilson: ORG\n",
      "a few days ago: DATE\n",
      "the Rev d G E Smith: FAC\n",
      "Orobanche: ORG\n",
      "Europe: LOC\n",
      "British: NORP\n",
      "Edinburgh: GPE\n",
      "Advocate: ORG\n",
      "Herbarium: ORG\n",
      "Noyau: ORG\n",
      "Christy Jr\n",
      ": PERSON\n"
     ]
    }
   ],
   "source": [
    "for entity in document.ents:\n",
    "    print(f'{entity.text}: {entity.label_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy of the labelling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Named Entities in JSON Format\n",
    "We can export these named entities in a JSON format, which can be saved in a file or used as input to other spaCy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary form of the document data \n",
    "doc_dict = document.to_json()\n",
    "doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the named entities item\n",
    "ents_dict = {key: value for (key, value) in doc_dict.items() if key == 'ents'}\n",
    "ents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a module for handling json\n",
    "import json\n",
    "\n",
    "# Export the named entities dictionary in json format\n",
    "json.dumps(ents_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Visualising Named Entities with displaCy\n",
    "\n",
    "The list above could be useful, but it is much easier as a human to understand how accurate the NER has been if we can see where the named entities fall within the context of the document.\n",
    "\n",
    "Fortunately, spaCy provides a nice visualiser called **displacy** that does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>I am ashamed that I have never before acknowledged the receipt of the very valuable packet of specimens you were so kind as to send me. Having now got my plants up from Cheshire I shall lose no time in making up a parcel for you. By some mistake the packet containing my \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Irish\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " plants is not with the rest. Of these the only really rare ones are \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Arbutus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " unedo, Stachys ambigua and \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trichomanes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " brevisetum. The \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " and last I gathered with \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wilson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " so you have perhaps already received them from him but the other I think he did not find. I shall therefore if they do not arrive in time for this parcel enclose them in another before the season is over as there are some of your desiderata of which I have no duplicates by me but which I can easily procure in the ensuing \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Spring\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and Summer.</br>In sending you parcels I shall not conform myself strictly to your desiderata but send you duplicates of rare or local plants which if you already possess you can give to the best Botanists of the Class or dispose of in exchanges or in any other way you think fit.</br>I received a very long and interesting letter from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wilson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    a few days ago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " full of valuable remarks on various plants. I also had a very precious parcel of specimens from \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Rev d G E Smith\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " containing among others Cyperus longus and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Orobanche\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " caryophyllacea. Is he a correspondent of yours? I think he could send you a good many rare plants.</br>If you are not already acquainted with my friend Mr Arnott of Edinburgh I strongly advise you to open a correspondence with him.</br>He has botanized extensively with M r Bentham in the South of France and Pyrenees and wants to send you a very valuable collection of the plants of that part of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Europe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " as well as some rare \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    British\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " ones.</br>I know he is in want of some of the rare Cambridge Plants and when I was in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Edinburgh\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " he talked of writing to you and offering to exchange Exotic Plants for these.</br>Perhaps he has already done so. His address is G A Walker Arnott Esq., \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Advocate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", 7 S t John Street Edinburgh.</br>Excuse the freedom of my remarks – I am only anxious to shew you every opportunity of benefiting your \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Herbarium\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". By the bye would any seeds from Barbadoes be useful to your Botanic Garden? I have just received some but unfortunately without their scientific names.</br>Some of the local names are odd enough as “Old Maids” – “Pigeons dung” &amp;c &amp;c &amp;c Perhaps you will let me know.</br>There is one marked “plant from which \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Noyau\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is made” – it is evidently the seed of a species of Ipomea or Convolvulus and besides abounding in prussic acid contains a great deal of saccharine matter. I enclose a few if you like to grow it.</br>Believe me | yours very truly | W \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Christy Jr\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(document, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> **EXERCISE**: Inspect the visualisation above and make a note of what spaCy has predicted well and what it is has got wrong. Has it mislabelled some tokens? Has it missed some entities out? Has it got some of the spans wrong?\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also **save** the results of a visualisation as an HTML file to review later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8270"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a module that helps with filepaths\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a filepath for the output file\n",
    "output_file = Path(\"../results/ent_viz.html\")\n",
    "\n",
    "# Give the document a title for reference\n",
    "document.user_data[\"title\"] = \"Letter from William Christy, Jr., to John Henslow, 26 February 1831\"\n",
    "\n",
    "# Output the visualisation as HTML\n",
    "html = displacy.render(document, style='ent', jupyter=False, page=True)\n",
    "\n",
    "# Write the HTML to the output file\n",
    "output_file.open(\"w\", encoding=\"utf-8\").write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now navigate to the file in the Jupyter file listing, or click on this link to view the file: [`output/ent_viz.html`](output/ent_viz.html). (Note that this file will not exist until you have run the code above!)\n",
    "\n",
    "The makers of spaCy also run a [named entity visualizer demo](https://explosion.ai/demos/displacy-ent) on their website, where you can experiment with different texts without writing any code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> **EXERCISE**: Go back to the code where we parsed the XML of the letter with Beautiful Soup and try running the NER on some other letters. Remember you need to run all the following cells in order.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "- A **named entity** is defined as any type of real-world object or concept that is assigned a name or proper name.\n",
    "- The Python library **BeautifulSoup** can parse text in XML, which is useful for extracting the text of Henslow letters marked up in TEI.\n",
    "- The Python library **spaCy** can predict named entities by using an English language model that has been pre-trained using machine learning on a corpus of general modern texts.\n",
    "- spaCy can recognise certain **pre-defined** named entities 'out of the box'.\n",
    "- The **predictions** made by spaCy's default model are quite good but suffer from some inaccuracies.\n",
    "- spaCy can **visualise** the named entity labels within the context of the original text so we can better assess the accuracy of the predictions.\n",
    "\n",
    "In the [next notebook](3-principles-of-machine-learning-for-named-entities.ipynb) we will look in more detail at how machine learning **models** make **predictions** about named entities, how to improve the predictions by **training** the model and how to create **training data** by labelling data manually. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
